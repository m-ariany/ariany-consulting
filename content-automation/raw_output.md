People first reached for chatbots at work. A new, large study shows the center of gravity has moved to our personal lives—and fast.

## Why this matters now

ChatGPT reportedly serves about 700 million weekly active users. So changes in how people use it ripple into how many of us write, plan, learn, and decide. OpenAI, working with a Harvard economist, analyzed real usage at scale and shared a preliminary report through the National Bureau of Economic Research (NBER). The headline: more diverse users, more varied tasks, and a clear tilt toward everyday life.

In our experience, that shift has been visible for months. Around spring, “help me plan a move” started to edge out “fix this script” in many prompts we reviewed.

Sources: NBER working paper “How People Use ChatGPT” (preliminary; access requires an institutional email), and Anthropic’s third Economic Index.

## How the study ran

The authors pulled a random sample of 1.58 million messages from over 1.1 million conversations. The window ran from May 2024 to July 2025.

They looked only at messages from logged‑in, adult consumers. Enterprise traffic and minors were out of scope.

For demographics, they grouped users by self‑reported age, geography, and a gender proxy based on first names the team marked as typically masculine, feminine, or indeterminate.

For content, they labeled each message by topic, by general intent—“asking,” “doing,” or “expressing”—and by task, such as writing or coding.

## What we saw in the data

The picture is clear: young adults lead usage, women’s participation is rising, and personal tasks now dominate.

- Young adults drove activity. Users aged 18–25 sent 46 percent of messages. People aged 26–66 were more likely to use ChatGPT for work.

- The gender balance shifted. Messages from users with names classified as typically feminine rose from 37 percent in January 2024 to 52 percent by June 2025. Women may now outnumber men on the consumer product.

- Asking beat doing or expressing. The most common intents were practical guidance at 28.3 percent and writing at 28.1 percent. Seeking information was close behind at 21.3 percent.

- Personal use surged. In June 2024, messages split roughly half and half between work and non‑work. By July 2025, about 73 percent likely were not work related. Volume grew overall: likely non‑work messages rose by around eight times, while work messages grew by more than three times.

- Within non‑work, people sought information (24.4 percent) and practical guidance (28.8 percent). At work, most requests were writing tasks—often editing, critiquing, translating, or transforming text rather than generating fresh copy.

Table: key signals at a glance (study sample; consumer users over 18)
- Age 18–25 share: 46%
- “Feminine” name share: 37% (Jan 2024) → 52% (Jun 2025)
- Non‑work share: ~73% (Jul 2025)
- Top intents: guidance 28.3%, writing 28.1%, information 21.3%
Caption: The mix moved toward personal guidance and information seeking.

## Where this lines up with other evidence

OpenAI calls this the largest chatbot usage study to date. Peers report similar patterns. Anthropic’s third Economic Index finds Claude API users are far more likely to automate tasks than consumer users. Claude use still leans computational and mathematical, yet education, arts and media, and office or admin support are climbing.

Together, these results point to broader adoption and a wider set of needs than the early, tech‑heavy crowd.

## How to try this in your own work

You do not need a massive dataset to learn from this shift. Run a small, structured pass on your logs or team habits.

- Tag a one‑week sample by intent—asking, doing, expressing—and by work versus personal. Compare shares.
- Break writing into “transform” versus “generate.” See where users struggle and add templates or examples.
- Add a “practical guidance” path in your UI. Keep answers direct, with sources and next steps.
- Review privacy flows for personal tasks. Make data retention clear and easy to control.
- Track one metric for three weeks, like “share of non‑work prompts,” and ship one improvement per week.

## Risks and limits

- Gender inference is a proxy. Classifying by first names can mislabel people and misses non‑binary users.
- The sample excludes enterprise and minors. Consumer logs do not reflect business behavior or school use.
- Labels can blur. “Work” versus “personal,” and “ask” versus “do,” are sometimes hard to separate.
- It is a preliminary report. Methods and numbers may change; access requires an institutional email.

We see one trade‑off up close: supporting personal advice raises safety and sensitivity. The fix is simple but strict—clear disclosures, cite sources, and fast routes to human help when stakes are high.

## Bottom line

ChatGPT is shifting from an office tool to a daily companion. That opens new value in guidance and planning, but it raises higher bars on privacy and care. This week, tag a small slice of your prompts by intent and work versus personal, then ship one change that makes practical guidance clearer—and safer.